{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Systems in Agriculture (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Image Representation (Images as Arrays)\n",
    "We define how images are represented as arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import relevant Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Load and display an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image = '.\\img\\class-crew.jpg'\n",
    "\n",
    "# read the image from the directory\n",
    "img = cv.imread(path_to_image)\n",
    "\n",
    "# Convert from BGR (OpenCV's default) to RGB (Matplotlib's default)\n",
    "img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# display image\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Explore image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image properties:')\n",
    "print(f'Image type: {type(img_rgb)}')\n",
    "print(f'Image shape: {img_rgb.shape}')\n",
    "print(f'Image size: {img_rgb.size}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Basic Image Processing\n",
    "\n",
    "1. Image cropping\n",
    "2. Image resizing\n",
    "3. Splitting image channels\n",
    "4. Merging image channels\n",
    "5. Converting to different color spaces\n",
    "6. Pixel value distribution (image histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Image cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to isolate Luke head!!\n",
    "\n",
    "# img_cropped = img_rgb[200:300, 200:300]\n",
    "# plt.imshow(img_cropped)\n",
    "# print(f'Cropped image shape: {img_cropped.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore the cv.resize function\n",
    "\n",
    "# print(f'Original image shape: {img_rgb.shape}')\n",
    "# print(f'Resized image shape: {img_resize.shape}')\n",
    "\n",
    "# plt.imshow(img_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Splitting the image channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: RGB images have three (3) channels, use cv.split to isolate each channel and then display them all\n",
    "\n",
    "# channels = ??\n",
    "# titles = ??\n",
    "\n",
    "# plt.figure(figsize=(16, 6))\n",
    "# plt.subplot(1,4,1)\n",
    "# plt.imshow(img_rgb), plt.title(titles[0])\n",
    "\n",
    "# for i in range(len(channels)):\n",
    "#     plt.subplot(1,4,i+2)\n",
    "#     plt.imshow(channels[i])\n",
    "#     plt.title(titles[i+1])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merging image channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: What can be split can be merged. Use the cv.merge function to merge the individual channels together\n",
    "\n",
    "# merged_img_rgb = ??\n",
    "# merged_img_bgr = ??\n",
    "\n",
    "#TODO: Does the order of merging matter? Find out!\n",
    "\n",
    "# titles = ['Original Image', 'Merged RGB', 'Merged BGR']\n",
    "# plt.figure(figsize=(16, 6))\n",
    "# plt.subplot(1,3,1)\n",
    "# plt.imshow(img_rgb), plt.title(titles[0])\n",
    "# plt.subplot(1,3,2)\n",
    "# plt.imshow(merged_img_rgb), plt.title(titles[1])\n",
    "# plt.subplot(1,3,3)\n",
    "# plt.imshow(merged_img_bgr), plt.title(titles[2])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Converting to different color spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Explore different color spaces. Plot the original image in at least 3 other color spaces\n",
    "\n",
    "# Reference: https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Pixel value distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Every pixel has a value (0, 255), let's explore the pixel value distribution\n",
    "\n",
    "# TODO: 1. convert to grayscale\n",
    "# img_gray = ??\n",
    "\n",
    "\n",
    "# TODO: 2. find the min and max pixel value\n",
    "# print(f'Min and Max pixel values are: [{np.min(img_gray)}, {np.max(img_gray)}]')\n",
    "\n",
    "\n",
    "# TODO: 3. create and plot the pixel value distribution as an image histogram\n",
    "histSize = 256\n",
    "histRange = (0, 255)\n",
    "# plt.hist(img_gray.flatten(), bins=histSize, range=histRange, alpha=1)\n",
    "# plt.xlabel('Pixel Intensity'), plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "# TODO: 4. determine the cumulative distribution and plot it against the pixel value distribution\n",
    "# hist, bins = np.histogram(img_gray.flatten(), histSize, histRange)\n",
    "# cdf = hist.cumsum()\n",
    "# cdf_normalized = cdf * float(hist.max()) / cdf.max()\n",
    "\n",
    "# plt.plot(cdf_normalized, color = 'b')\n",
    "# plt.hist(img_gray.flatten(), bins=histSize, range=histRange, alpha=1, color = 'r')\n",
    "# plt.xlim([0,256])\n",
    "# plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "# plt.xlabel('Pixel Intensity'), plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Image Enhancement\n",
    "\n",
    "1. Histogram equalization\n",
    "2. Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Histogram equalization\n",
    "\n",
    "Resource: https://docs.opencv.org/4.x/d5/daf/tutorial_py_histogram_equalization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import orange image file: 'orange.jpg'\n",
    "img_gray = cv.imread('.\\\\img\\\\noisy-oranges.jpg', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(img_gray, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute and plot the histogram and the cummulative distribution (use similar code as above)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Using the cv.equalizeHist, perform histogram equalization and plot the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute and plot the histogram and the cummulative distribution of the equalized image (use similar code as above)\n",
    "\n",
    "# Can you spot the difference??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Image Filtering (smoothing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource: https://docs.opencv.org/3.4/d4/d13/tutorial_py_filtering.html \n",
    "img = cv.imread('.\\\\img\\\\noisy-oranges.jpg')\n",
    "\n",
    "# TODO: Play around with different filters to get a good outcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4. Pixel-wise Image Segmentation\n",
    "\n",
    "1. Monochrome image classification (manual approach)\n",
    "2. Monochrome image classification (adaptive approach and Otsu)\n",
    "3. Color image classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Monochrome image classification (manual approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource: https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html\n",
    "\n",
    "# TODO: Import orange.jpg \n",
    "\n",
    "# TODO: Inspect the pixel value distribution to determine a good threshold\n",
    "\n",
    "# TODO: Use cv.threshold to apply a binary threshold on the image and plot the outcome \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Monochrome image classification (adaptive approach and Otsu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource: https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html\n",
    "\n",
    "# TODO: Use cv.adaptiveThreshold to apply a binary threshold on the image and plot the outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource: https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html\n",
    "\n",
    "# TODO: Use the otsu method to apply a binary threshold on the image and plot the outcome\n",
    "\n",
    "# TODO: What are your observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Color image classification\n",
    "\n",
    "Resource: https://realpython.com/python-opencv-color-spaces/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Follow the resource above to define a color mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Could you apply the Otsu approach to this as well? Give it a try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Morphological operations are super helpful in denoising and rounding out your mask.\n",
    "# Resource: https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Bounding box and segmentation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use a combination of cv.findContours, cv.drawContours and OpenCV's bitwise operations to obtain a bounding box and segmentation visualization as in the image below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Solution\n",
    "\n",
    "<img src=\".\\img\\solution1.png\" width=\"800\">\n",
    "\n",
    "<img src=\".\\img\\solution2.png\" width=\"400\">\n",
    "\n",
    "\n",
    "#### TODO\n",
    "1. Generate an object detection solution for \"orange.jpg\" AND either \"orange-2.jpg\" or \"orange-3.jpg\" \n",
    "2. Generate a plot showing the prediction vs the ground truth for each image\n",
    "3. Calculate the evaluation metric (mean average precision) for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_ground_truth_ann, calculate_map\n",
    "\n",
    "# Our goal here is to evaluate the segmentation and object detection prediction against ground truth data for the image\n",
    "\n",
    "# TODO: Use cv.boundingRect to get the bounding box info from the contour you generated above\n",
    "\n",
    "# prediction_bbox = []\n",
    "# for contour in contours:\n",
    "#     x, y, w, h = cv.boundingRect(contour)\n",
    "#     prediction_bbox.append([x, y, x + w, y + h])\n",
    "\n",
    "# Here we have provided a helper function to extract the ground truth bbox for the images\n",
    "# image_name = 'example-image.jpg'\n",
    "# ground_truth_bbox = get_ground_truth_ann(image_name=image_name, show=False)\n",
    "\n",
    "# print(f'ground_truths = {ground_truth_bbox}')\n",
    "# print(f'predictions = {prediction_bbox}')\n",
    "\n",
    "\n",
    "# TODO: plot the results\n",
    "# img_bbox = img.copy()\n",
    "\n",
    "# for gt in ground_truth_bbox:\n",
    "#     gt = [int(v) for v in gt]\n",
    "#     cv.rectangle(img_bbox, (gt[0], gt[1]), (gt[2], gt[3]), (0, 255, 0), 2)\n",
    "\n",
    "# for pd in prediction_bbox:\n",
    "#     pd = [int(v) for v in pd]\n",
    "#     cv.rectangle(img_bbox, (pd[0], pd[1]), (pd[2], pd[3]), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "# plt.imshow(img_bbox)\n",
    "# plt.title(\"Ground truth vs predicted Bbox\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the calculate_map helper function to calculate the average precision of your object detection pipeline\n",
    "# mAP = calculate_map(ground_truth_bbox, prediction_bbox, iou_threshold=0.7)\n",
    "# print(mAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
